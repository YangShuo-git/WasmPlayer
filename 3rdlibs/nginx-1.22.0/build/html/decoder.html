<body>

    <head>
        <meta charset="UTF-8">
        <title>Web播放器</title>
    </head>

    <div><canvas id="glcanvas" width="640" height="480"></canvas></div>

    <script>
        function VideoPlay() 
        {
            let ptr; // 解码器句柄,对应c++层的HANDLE

            ptr = Module._initDecoder();

            var js_h264_buf =  new Uint8Array(event.data);
            var js_h264_len = js_h264_buf.length;
            console.log("收到一帧数据,长度为:" ,js_h264_len);

            var dst = Module._GetBuffer(ptr,js_h264_len);    // 通知C/C++分配好一块内存用来接收JS收到的H264流.
            HEAPU8.set(js_h264_buf,dst);    // 将JS层的数据传递给C/C++层.

            if( Module._Decode(ptr,js_h264_len) >= 0 )
            {
                var width  = Module._GetWidth(ptr);
                var height = Module._GetHeight(ptr);
                var renderlength = width * height * 3 / 2;
                console.log("解码成功 , width:%d height:%d" ,width,height);

                // 不推荐 YUV->RGB,RGB贴图
                // 这种方式不推荐，因为YUV-RGB,RGB贴图耗费的时间，有可能会超过解码的时间.

                var yuv_wasm_data = Module._GetRenderData(ptr); // 得到C/C++生成的YUV数据.
                // 将数据从C/C++层拷贝到JS层
                var RenderBuffer = new Uint8Array ( Module.HEAPU8.subarray(yuv_wasm_data,yuv_wasm_data + renderlength + 1) );
                render(RenderBuffer,width,height);
            }
            else
            {
                console.log("解码失败.");
            }
            
        }
    </script>

    <script async src=ffmpeg.js></script>

    

    <p>
        <tr>
            <th><input type="button" onclick="VideoPlay()" value="PLAY"></th>
        </tr>
    </p>

</body>